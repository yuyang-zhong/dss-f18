{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSS 11/14 Introductory Statistics.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "AGwrWmmEZQzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introductory Statistics Workshop"
      ]
    },
    {
      "metadata": {
        "id": "r6vrHUylZQzt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Welcome to the workshop! Today you will be learning about:\n",
        "\n",
        "1. Causation, Correlation, Different types of studies, and Random Sampling\n",
        "2. Hypothesis Testing using p-values\n",
        "3. Histograms\n",
        "4. Confidence Intervals\n",
        "5. SD, Mean, and the Central Limit Theorem\n",
        "\n",
        "Throughout this notebook we use a python library called **Pandas** in order to store and display our data. If you would like to learn how to use Pandas in more detail, check out our Python Libraries workshop materials: http://bit.ly/2oY6BOP\n",
        "\n",
        "https://pypi.python.org/pypi/datascience/"
      ]
    },
    {
      "metadata": {
        "id": "BD-JQqsSbBNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bHlHGpYOeBsK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **About the dataset:**\n",
        "\n",
        "In 2013, students of the Statistics class at FSEV UK were asked to invite their friends to participate in this survey.\n",
        "\n",
        "The data file (responses.csv) consists of 1010 rows and 150 columns (139 integer and 11 categorical).\n",
        "\n",
        "Each row represents a young person's response. Each column is a question/topic on which each person had to give a rating or information. This link has more detailed description of the dataset: [Young People Survey](https://www.kaggle.com/miroslavsabo/young-people-survey).\n",
        "\n",
        "Here is an example of convenience sampling, which isn't as accurate as pure simple random sampling, but is still reliable enough to formulate valid conclusions from. You are making conclusions of this data and not necessarily trying to generalize the conclusions to the whole population of young people, so convenience sampling is ok. Many times in real life, when conducting observational studies, you will be working with data that came from convenience sampling.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dLndCu4hWHJL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Your code could look like\n",
        "\n",
        "# Import data :\n",
        "#data_all = pd.read_csv('DSS 4-4 Stat Workshop/responses.csv')\n",
        "#or\n",
        "#data_all = pd.read_csv('folder_name/responses.csv')\n",
        "\n",
        "\n",
        "\n",
        "columns = pd.read_csv(\"https://raw.githubusercontent.com/krutikaingale/Data-Science-Society/master/columns.csv\")\n",
        "data_all = pd.read_csv(\"https://raw.githubusercontent.com/krutikaingale/Data-Science-Society/master/responses.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7LXQn-b2btBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jSVUx1Lifa-K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now let's study spending habits, specifically those of males and females**"
      ]
    },
    {
      "metadata": {
        "id": "Ak4BdXkCfvIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#We pick the columns that relate to spending, and pick the gender column\n",
        "#Columns are indexed at 0. So we can reference columns by their index 0,1,2,...149\n",
        "spending  = data_all.iloc[:,134:140] #.iloc[:, a:b] chooses columns indexed at a up to but not including b\n",
        "spending['Gender'] = data_all['Gender']\n",
        "spending"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rArDA-EEgqIh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The columns represent these questions:**\n",
        "\n",
        "1) I enjoy going to large shopping centres.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)\n",
        "\n",
        "2) I prefer branded clothing to non branded.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)\n",
        "\n",
        "3) I spend a lot of money on partying and socializing.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)\n",
        "\n",
        "4) I spend a lot of money on my appearance.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)\n",
        "\n",
        "5) I spend a lot of money on gadgets.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)\n",
        "\n",
        "6) I will hapilly pay more money for good, quality or healthy food.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)"
      ]
    },
    {
      "metadata": {
        "id": "lyPoQYAZku1O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**From now on, when we reference \"male and female spending\", we mean \"male and female spending ratings\"**"
      ]
    },
    {
      "metadata": {
        "id": "pfRq9Jh1hEC5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#We can tell entire dataframe to drop NaN values and convert them to 0's.\n",
        "spending.fillna(0, inplace = True)\n",
        "spending.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JkGsGcIJfJ6F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Group Question***: What do larger ratings mean for spending habits? What do smaller ratings mean for spending habits? How can we combine all the responses for all 6 questions into 1 informative response?"
      ]
    },
    {
      "metadata": {
        "id": "5fnnEpZlhRaB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**In the table, larger numbers/ratings in essence implies that the person spends more. So let's sum up all the spending of each person into a single spending column. The resulting summed column will be of type float.**"
      ]
    },
    {
      "metadata": {
        "id": "KNb0l9I7hU4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Basically larger numbers/ratings means the person spends more\n",
        "#So let's sum up all the spending of each person into a single spending column. Resulting column will be of float type\n",
        "spending_amount = spending.iloc[:, 0] + spending.iloc[:, 1] + spending.iloc[:, 2] + spending.iloc[:, 3] + spending.iloc[:, 4] + spending.iloc[:, 5] \n",
        "total_df = pd.DataFrame(spending_amount).rename(columns = {0: 'Spending Amount'})\n",
        "total_df['Gender'] = spending['Gender']\n",
        "total_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-_86w0oiU7x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now let's create a table with female spending and a table for male spending.**"
      ]
    },
    {
      "metadata": {
        "id": "3S3Qq-BuiyKo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#female spending data frame\n",
        "female_spending = total_df[total_df['Gender'] == 'female']\n",
        "female_spending"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mxjPb2qMiyRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#male spending data frame\n",
        "male_spending = total_df[total_df['Gender'] == 'male']\n",
        "male_spending"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OM3_glQxgwQq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Group Question***: Now which simulation method should we use (shuffling, bootsrapping, etc) and why? Could you give a basic outline of the simulation process?"
      ]
    },
    {
      "metadata": {
        "id": "CftCKfEfjIg_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now we want to stack the total spending of females on top of the spending of males and put it into a data frame. We do this so we can run our simulation of shuffling for our hypothesis test.**"
      ]
    },
    {
      "metadata": {
        "id": "mKC1dnhJjeHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "appended_spending = female_spending['Spending Amount'].append(male_spending['Spending Amount'], ignore_index=True)\n",
        "\n",
        "print(\"Number of Females: \", len(female_spending['Spending Amount']))\n",
        "print(\"Number of Males: \",len(male_spending['Spending Amount']))\n",
        "#These are only females and males, There are people who idenitfy otherwise in the actual dataset, but we're only focused on females and males\n",
        "final_spending = pd.DataFrame(appended_spending)\n",
        "final_spending\n",
        "#females are the first 593 rows, males are the next 411 rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbzoFlN_jvT_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The females are the first 593 rows, males are the next 411 rows. There are 1004 rows in total."
      ]
    },
    {
      "metadata": {
        "id": "6eu5rP04hQ-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Group Question***: What is a good test statistic to use and why? Remember we're trying to compare two groups."
      ]
    },
    {
      "metadata": {
        "id": "0IYC4bXyj_AB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's compare the spending of males and females. We can do this by subtracting the male and female average spending. This will serve as our test statistic : male average spending - female average spending.**"
      ]
    },
    {
      "metadata": {
        "id": "AJ_Ya7-LkCi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "observed_test_statistic = male_spending['Spending Amount'].mean() - female_spending['Spending Amount'].mean()\n",
        "observed_test_statistic\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_MQHUY0lQh-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The positive difference of 0.85 indicates that the male spending seems to be higher than the female spending, and that females may be more money-efficient than males. Higher ratings from the males implies that males don't mind spending more money.**"
      ]
    },
    {
      "metadata": {
        "id": "VnwYIS4il1Z6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Let's start our Hypothesis Test"
      ]
    },
    {
      "metadata": {
        "id": "Mrl9JYiqhel2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Group Question***: What is our null and alternative hypothesis?"
      ]
    },
    {
      "metadata": {
        "id": "bLDCJHkGl_zT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis**: There is no difference between male and female spending. The females' spendings are like a random sample of 593  out of all 1004 expenditures. If the males' average spending came out higher than that of the females, it is due to chance variation.\n",
        "\n",
        "**Alternative Hypothesis**: The males' spending being higher than the females' spending is not due to chance. There is something other than chance causing the difference between male and female spending."
      ]
    },
    {
      "metadata": {
        "id": "0_HhGJMvmele",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When you sample without replacement (by specifiying with_replacement=False) the same number of times as there are rows, you end up with a random shuffle of all the rows, which represents finding a new sample. Under the null hypothesis, differences in the female and male spending averages should be close to 0 (aka there is no difference between male and female spending). Under the null hypothesis, each new sample we get from shuffling the rows, male spending average - female spending average should be close to 0.\n",
        "\n",
        "**Overarching method**: We shuffle the rows of final_spending by random sampling. Choose the top 593 rows of resulting sampled dataframe to represent female spendings and find the average spending. The remaining 411 rows will represent male spending and find the average. \n",
        "\n",
        "**Our test statistic: male spending average - female spending average.**"
      ]
    },
    {
      "metadata": {
        "id": "AQC4PiWEnUeq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pseudocode:\n",
        "\n",
        "\n",
        "```\n",
        "Declare an test_statistics_array\n",
        "\n",
        "Repeat process 10,000 times to get 10,000 test statistics:\n",
        "\n",
        "   In one sample:\n",
        "   \n",
        "           We shuffle the rows of final_spending by random sampling. Choose the top 593 rows of resulting sampled dataframe \n",
        "           to represent female spendings and find the average spending. The remaining 411 rows will represent male spending \n",
        "           and find the average. \n",
        "           \n",
        "           this_sample's_test_statistic = male spending average - female spending average\n",
        "           \n",
        "           test_statistics_array.add on (this_sample's_test_statistic)\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "CzbBXD08oOq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "simulated_statistics = []\n",
        "repetitions = 10000\n",
        "\n",
        "for i in np.arange(repetitions):\n",
        "    shuffled = final_spending.sample(n = len(final_spending.index), replace=False)\n",
        "    female_mean = (shuffled.iloc[0:593])['Spending Amount'].mean()\n",
        "    male_mean = (shuffled.iloc[593:len(final_spending.index)])['Spending Amount'].mean()\n",
        "    test_statistic = male_mean - female_mean\n",
        "    simulated_statistics = np.append(simulated_statistics, test_statistic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0onHYu0goOyU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "simulated_statistics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2qt7pGRoXDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(simulated_statistics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9vJbu4zZogXN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our observed test statistic was 0.8549870139461575.\n",
        "\n",
        "**To calculate our p-value, we do empirical_P = np.count_nonzero(simulated_statistics >= observed_statistic)/repetitions**\n",
        "\n",
        "**P-value** : Chance (computed under the null hypothesis) of getting a test statistic equal to the one that was observed or more in the direction of the alternative. In our case, \"direction of the alternative\" means greater than or equal to 0.8549870139461575.\n",
        "\n",
        "**P-value** = (how many differences that we calculated under the null hypothesis are greater than what was observed in the beginning)/ total number of differences. By dividing we get the \"chance\" that we're looking for. We're trying to see if the observed test statistic is too extreme.\n"
      ]
    },
    {
      "metadata": {
        "id": "A4mGhdyCpCgL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "empirical_P = np.count_nonzero(simulated_statistics >= observed_test_statistic)/repetitions\n",
        "print('Observed Statistic:', observed_test_statistic)\n",
        "print('Empirical P:', empirical_P)\n",
        "\n",
        "results = pd.DataFrame(np.array(simulated_statistics)).rename(columns = {0 : 'Simulated Statistics'})\n",
        "results['Simulated Statistics'].plot(normed = True, kind='hist', color = 'navy')\n",
        "plt.xlabel('Difference in Spending (M-F)')\n",
        "plt.ylabel('Proportion')\n",
        "plt.title('Histogram of Differences Scores')\n",
        "\n",
        "plt.scatter(observed_test_statistic, 0, color='red', s=50);\n",
        "left = results['Simulated Statistics'].sort_values(ascending = True).quantile(0.025)\n",
        "right = results['Simulated Statistics'].sort_values(ascending = True).quantile(0.975)\n",
        "print('95% Confidence Interval:', left, \", \", right )\n",
        "plt.plot((left, right), (0, 0), 'yellow', lw = 8)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCWDef9viARp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Group Question***: What is the conclusion of our test and why? Explain.\n",
        "\n",
        "P VALUE = .0019"
      ]
    },
    {
      "metadata": {
        "id": "y9yIQ1U5r6HS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Under null hypothesis, male spending - female spending should be close to 0, since we assume male and female spending is the same. The above histogram does show that, since it is centered at 0.**\n",
        "\n",
        "\n",
        "However, we see the observed test statistic is very \"extreme\" and lies away from the heart of the distribution. **The observed test statistic, in red, is about 0.85, which means the male spending avergae - female spending average is positive. This suggests that the males spent more money than the females and that the females save more money.**\n",
        "\n",
        "**The p-value is 0.0019 and we use a p-value cutoff of 0.05 along with a 95% confidence interval.** \n",
        "Since **0.0019 < 0.05, and even < 0.01**,  we see that the **difference between male and female spending that was observed in the beginning is too extreme to have occurred by just chance**. There is something other than chance that caused the males to spend more than females.\n",
        "\n",
        "**So we reject the null hypothesis that male and female spending habits of the young people who took the survey are the same.**"
      ]
    },
    {
      "metadata": {
        "id": "Qz_562VpZQzu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualizing Data"
      ]
    },
    {
      "metadata": {
        "id": "EaKc9aERuA93",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Bar Charts"
      ]
    },
    {
      "metadata": {
        "id": "8VCJ7_YJnF7H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spending.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wYGruMPTpsIr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can analyze some of this data using a bar graph.\n",
        "\n",
        "### Question: What does the data tell us about people's willingness to spend more money on \"good\" food?\n",
        "### Answer: Use a bar graph - what are the categorical variables we'll use?\n",
        "\n",
        "<br>\n",
        "Notes:\n",
        "- can rearrange bars\n",
        "- can flip the orientation of the graph"
      ]
    },
    {
      "metadata": {
        "id": "kXfqn3ipnIt2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grouped = spending.groupby('Spending on healthy eating').count().iloc[:, :1]\n",
        "grouped.index = [\"\", 'Strongly Disagree', 'Disagree', 'Neutral', \"Agree\", \"Strongly Agree\"]\n",
        "grouped.index.names = ['Willing to spend more on food']\n",
        "grouped.columns = ['responses']\n",
        "\n",
        "# grouped = grouped.sample(6, replace=False) # We can rearrange bars and still read the graph\n",
        "\n",
        "grouped.plot(kind=\"barh\")   # barh to flip bar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XD2XS3lgt9UD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Histograms"
      ]
    },
    {
      "metadata": {
        "id": "r4zShRHZuGvF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data:** Top 200 highest grossing movies of all time."
      ]
    },
    {
      "metadata": {
        "id": "B-dCq-Ljuf7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "movies = pd.read_csv(\"https://raw.githubusercontent.com/carlocrza/Data_Science_Society/master/top_movies.csv\")\n",
        "movies.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uFcRUdLIZQzu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies.to_csv(\"testing.csv\")\n",
        "\n",
        "g = movies[['Studio', 'Title']].groupby(\"Studio\").count()\n",
        "plt.barh(g.index, g['Title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5INiB73dWAT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Say we wanted to know how many movies made more than `$`500 billion and how many made more than `$`600 million, etc. This is a distribution of the movie gross. We use a histogram.\n",
        "\n",
        "\n",
        "First, let's think about our x-axis: it will represent the amount of money made for movies. "
      ]
    },
    {
      "metadata": {
        "id": "qWYD5Yc-1foN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross = movies[['Gross (Adjusted)']].apply(lambda x: np.round(x/1e6, 2))['Gross (Adjusted)']\n",
        "\n",
        "min(gross), max(gross)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nMN7eYPU1Wsu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Okay so our x-axis will go from `$`338 to `$`1796. Let's divide this range into **bins of width 100**"
      ]
    },
    {
      "metadata": {
        "id": "KEMoofqT14FZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.histogram(gross, bins=np.arange(300,2001,100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKFCJZ7eyPM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross.hist(bins=np.arange(300,2001,100), figsize=(15,7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hIrbyV-X23yH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Y-axis above is the number of occurrences.\n",
        "\n",
        "Can have unequal bin widths. Sometimes this is useful.\n",
        "\n",
        "But problem: now it looks like there are a ton of movies that make more than 700 million."
      ]
    },
    {
      "metadata": {
        "id": "xpHQV10FvZxM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross.hist(bins=list(np.arange(300,700,100)) + [700,2000], figsize=(15,7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Pm5CzVc3MUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross.hist(bins=list(np.arange(300,700,100)) + [700,2000], figsize=(15,7), density=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IogJoSdc3Koj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now the y-axis represents \"DENSITY\" of Data. The height for the bin \\[700, 2000) is now very low because it has super-low density (think huge bin width but few entries). Compared to the bin 300-400 with only a width of 100 but ~70 entries. \n",
        "\n",
        "How is this useful?\n",
        "- Visually makes more sense: even with unequal bins, we can see that movies from 300-400 are much more common than movies above 700\n",
        "- The area of a bin = the percent of values that appear in that bin\n",
        "\n",
        "$\\mbox{area of bar} ~=~ \\mbox{percent of entries in bin}\\\\\n",
        "\\mbox{area of bar} ~=~ \\mbox{height of bar} \\times \\mbox{width of bin}$"
      ]
    },
    {
      "metadata": {
        "id": "ZAHOKz6Hu2f8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### QUESTION: What percent of movies make between `$`300 and `$`500 million dollars?"
      ]
    },
    {
      "metadata": {
        "id": "W3TROyUhvaAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# not yet\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "100*.0034 + 100*.003"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TO7THjrp5qKs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Types of Distributions"
      ]
    },
    {
      "metadata": {
        "id": "mfqxeQXM5spG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "  \n",
        "  <tr><td>SYMMETRIC:<br> Amount of data to the left and right of the mean are roughly equal.</td><td>SKEWED RIGHT: <br>\n",
        "1. tail of distribution is on the right hand side<br>\n",
        "  2. mean > median</td><td>SKEWED LEFT: <br>\n",
        "1. tail of distribution is on the left hand side<br>\n",
        "  2. mean &lt; median</td>\n",
        "  \n",
        "  <tr><td>\n",
        "\n",
        "<img src=\"https://www.siyavula.com/read/maths/grade-11/statistics/images/7588d6507c1315bd04332b326df7bec5.png\"></td>\n",
        "\n",
        "<td>\n",
        "\n",
        "<img src=\"https://www.siyavula.com/read/maths/grade-11/statistics/images/690b5a06e1e448c583a88be23f6c747f.png\"></td>\n",
        "\n",
        "<td>\n",
        "\n",
        "<img src=\"https://github.com/carlocrza/Data_Science_Society/blob/master/left_skewed.png?raw=true\" width=\"450\"></td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "O0adDJlh8Srv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question: Is our movies distribution symmetric, right, or left skewed?"
      ]
    },
    {
      "metadata": {
        "id": "nxFTq_v48ZXk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross.hist(bins=list(np.arange(300,2000,100)), figsize=(15,7), density=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wg-ZAxtfS7Rw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross.hist(bins=list(np.arange(300,2000,100)), figsize=(15,7), density=True)\n",
        "plt.axvline(np.mean(gross), color=\"red\")\n",
        "plt.axvline(np.median(gross), color=\"orange\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bvzzZpqmThT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.mean(gross), np.median(gross)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m-IQ_n9faFFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Standard Deviation\n",
        "\n",
        "Root mean square of deviations from average.\n",
        "\n",
        "Compute the Standard Deviation for our Adjusted Gross data from movies. That is, what is the SD of the data we plotted a histogram of?"
      ]
    },
    {
      "metadata": {
        "id": "ZFXIPnFn5D-w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.mean(gross)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pAYA1ZHRaW5c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "deviations = gross - np.mean(gross)\n",
        "deviations.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rXst9FkYaisT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "squared_deviations = deviations**2\n",
        "squared_deviations.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWsoYI1UanTy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean_squared_deviations = np.mean(squared_deviations)\n",
        "\n",
        "standard_deviation = np.sqrt(mean_squared_deviations)\n",
        "\n",
        "standard_deviation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cDmP2d0Sa0sB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hint for the future ;)\n",
        "np.std(gross)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnMr2f1_PM1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross.hist(bins=list(np.arange(300,2000,100)), figsize=(15,7), density=True)\n",
        "plt.axvline(np.mean(gross), color=\"red\")\n",
        "plt.plot((np.mean(gross), np.mean(gross)+np.std(gross)), (0, 0), 'yellow', lw = 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jj1ImRrubzOc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's see Standard Deviation on a symmetric (normal) distribution.\n",
        "\n",
        "The heights of people tend to be symmetrically distributed. Let's look at heights of mothers from a sample."
      ]
    },
    {
      "metadata": {
        "id": "16Sh7BXGcTZu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv(\"https://raw.githubusercontent.com/carlocrza/Data_Science_Society/master/baby.csv\")\n",
        "heights = sample['Maternal Height']\n",
        "heights.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYUHBosqce0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(heights, bins=20, kde=False) # set kde=True to see curvature\n",
        "\n",
        "plt.axvline(np.mean(heights), color=\"red\")\n",
        "plt.axvline(np.median(heights), color=\"orange\")\n",
        "\n",
        "plt.axvline(np.mean(heights) + 2*np.std(heights), color=\"green\")\n",
        "plt.axvline(np.mean(heights) - 2*np.std(heights), color=\"green\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1wU9-SGJhe_K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Central Limit Theorem\n",
        "\n",
        "### The distribution of the sum or average of a sample drawn with replacement will be roughly symmetric\n",
        "\n",
        "- use large random sample\n",
        "- will always work! regardless of original sample distribution"
      ]
    },
    {
      "metadata": {
        "id": "FCm6evEshvmQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For example, let's go back to our Gross returns for our movies data.\n",
        "\n",
        "This was the original distribution:"
      ]
    },
    {
      "metadata": {
        "id": "5nviyJ0Qibud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n5Jqfyash19b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gross.hist(bins=list(np.arange(300,2000,100)), figsize=(15,7), density=True) # switch to 10, 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7xWi6aZh1Tj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clearly it's not a normal distribution as we saw before. But if we continuously draw samples with replacement from the data and take their average or sum, we'll get a symmetric distribution!"
      ]
    },
    {
      "metadata": {
        "id": "AmFMnspLh1iF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#original data\n",
        "gross\n",
        "\n",
        "repetitions = 10000\n",
        "sample_size = 30\n",
        "means = np.array([])\n",
        "\n",
        "for i in np.arange(repetitions):\n",
        "  sample = gross.sample(sample_size)\n",
        "  new_mean = np.mean(sample)\n",
        "  means = np.append(means, new_mean)\n",
        "\n",
        "means = pd.Series(means)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "501kWE4NkR1L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "means.hist(bins=20, figsize=(15,7), density=True)\n",
        "\n",
        "# plt.axvline(np.mean(means), color=\"red\")\n",
        "# plt.axvline(np.median(means), color=\"orange\")\n",
        "\n",
        "# plt.axvline(np.mean(means) + np.std(means), color=\"green\")\n",
        "# plt.axvline(np.mean(means) - np.std(means), color=\"green\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Ws1vNtI9MN2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.mean(gross)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qNbiqeqjk47K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Allows us to answer questions about our original data?\n",
        "\n",
        "Say we didn't have our original data and only samples of it, this allows us to answer what is the average gross return of the movies. Even without ever calling np.mean on the data.\n",
        "\n",
        "Useful if you think about huge theoretical datasets that can't exist - like the US population. You can't record every single person and then take the mean, you can only take samples of the US population. However, if you take enough samples you can create this normal distribution and the mean of the normal distribution is the mean of the original population.\n",
        "\n",
        "Real world example: suppose we are trying to determine how an election will turn out. We take a poll and find that in our sample, 80% of people would vote for candidate A over candidate B. Of course, we have only observed a small sample of the overall population. What percent of people in the whole population want to vote for candidate A? The central limit theorem tells us that if we ran the poll over and over again, the resulting guesses would be normally distributed around the true population value.\n",
        "\n",
        "* Note that this works because % is considered a 'sum'"
      ]
    },
    {
      "metadata": {
        "id": "4K-VbbVtpl86",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Correlation"
      ]
    },
    {
      "metadata": {
        "id": "9jQ4B462q6cQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Correlation does not equal Causation"
      ]
    },
    {
      "metadata": {
        "id": "xRfHu_yiMowt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Consider the scatter plot below which plots Amazon stock prices against Coca Cola stock prices? As you can see they are positively correlated - as Amazon stock increases, Coke stock increases. Does that mean better performance by amazon causes Coke to do better?"
      ]
    },
    {
      "metadata": {
        "id": "SqG6yNP9poSO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stocks = pd.read_csv(\"https://raw.githubusercontent.com/carlocrza/Data_Science_Society/master/stock.csv\")\n",
        "stocks['in'] = stocks.index\n",
        "plt.scatter(stocks['AMZN Closing Price'], stocks['KO Closing Price'], s=4)\n",
        "plt.xlabel(\"Amazon Stock\")\n",
        "plt.ylabel(\"Coca Cola Stock\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NmhK156nq-2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(stocks.index, stocks['KO Closing Price'], s=4)\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Coca Cola Stock\")\n",
        "plt.plot(np.unique(stocks.index), np.poly1d(np.polyfit(stocks.index, stocks['KO Closing Price'], 1))(np.unique(stocks.index)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jff4QfdPwLJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# let's find the linear function manually\n",
        "\n",
        "def error(slope_and_intercept):\n",
        "    slope = slope_and_intercept[0]\n",
        "    intercept = slope_and_intercept[1]\n",
        "    x = stocks['in']\n",
        "    y = stocks['KO Closing Price']\n",
        "    fitted = slope*x + intercept\n",
        "    return np.mean((y - fitted) ** 2)\n",
        "  \n",
        "error([1, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TxkPce_SvpFW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "minimize(error, [1, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dKLKI8r7xgZR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def equation(x):\n",
        "  return 1.09444470e-02 * x + 1.27460402e+01\n",
        "  \n",
        "x = np.arange(2500)\n",
        "plt.plot(x, equation(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HmLRNkPKZQzy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Please [leave feedback here](https://docs.google.com/forms/d/e/1FAIpQLSfoDgUzuvkkiq4lR5MvodDK0ZLr7aCv9DA3yUJpnFSiu1i3tg/viewform?usp=sf_link). Thank you!!"
      ]
    },
    {
      "metadata": {
        "id": "V_IIFok8ZQzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}